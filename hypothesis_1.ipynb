{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dfe3eec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_floor</th>\n",
       "      <th>state</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>big_market_raion</th>\n",
       "      <th>total_revolving_bal</th>\n",
       "      <th>market_count_1500</th>\n",
       "      <th>leisure_count_3000</th>\n",
       "      <th>total_ct_chng_q4_q1</th>\n",
       "      <th>water_1line</th>\n",
       "      <th>railroad_station_walk_km</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_open_to_buy</th>\n",
       "      <th>build_year</th>\n",
       "      <th>incineration_raion</th>\n",
       "      <th>full_sq</th>\n",
       "      <th>total_relationship_count</th>\n",
       "      <th>detention_facility_raion</th>\n",
       "      <th>build_count_mix</th>\n",
       "      <th>railroad_terminal_raion</th>\n",
       "      <th>__churn</th>\n",
       "      <th>__price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>no</td>\n",
       "      <td>1906</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.694</td>\n",
       "      <td>no</td>\n",
       "      <td>5.419893</td>\n",
       "      <td>...</td>\n",
       "      <td>1996.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>5.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>no</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.693</td>\n",
       "      <td>no</td>\n",
       "      <td>3.411993</td>\n",
       "      <td>...</td>\n",
       "      <td>1338.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>no</td>\n",
       "      <td>2153</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.831</td>\n",
       "      <td>no</td>\n",
       "      <td>1.277658</td>\n",
       "      <td>...</td>\n",
       "      <td>2411.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>5.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>no</td>\n",
       "      <td>1806</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.638</td>\n",
       "      <td>no</td>\n",
       "      <td>4.291432</td>\n",
       "      <td>...</td>\n",
       "      <td>9255.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>13.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>no</td>\n",
       "      <td>753</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.902</td>\n",
       "      <td>no</td>\n",
       "      <td>0.853960</td>\n",
       "      <td>...</td>\n",
       "      <td>3318.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>77</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>16.331452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_floor  state marital_status big_market_raion  total_revolving_bal  \\\n",
       "0        NaN    NaN         Single               no                 1906   \n",
       "1        NaN    NaN        Married               no                   12   \n",
       "2        NaN    NaN        Married               no                 2153   \n",
       "3        NaN    NaN        Married               no                 1806   \n",
       "4        NaN    NaN        Married               no                  753   \n",
       "\n",
       "   market_count_1500  leisure_count_3000  total_ct_chng_q4_q1 water_1line  \\\n",
       "0                  1                   0                0.694          no   \n",
       "1                  0                   6                0.693          no   \n",
       "2                  5                   0                0.831          no   \n",
       "3                  2                   0                0.638          no   \n",
       "4                  2                  40                0.902          no   \n",
       "\n",
       "   railroad_station_walk_km  ... avg_open_to_buy  build_year  \\\n",
       "0                  5.419893  ...          1996.9         NaN   \n",
       "1                  3.411993  ...          1338.4         NaN   \n",
       "2                  1.277658  ...          2411.5         NaN   \n",
       "3                  4.291432  ...          9255.9         NaN   \n",
       "4                  0.853960  ...          3318.2         NaN   \n",
       "\n",
       "   incineration_raion  full_sq total_relationship_count  \\\n",
       "0                  no       43                        5   \n",
       "1                  no       34                        3   \n",
       "2                  no       43                        6   \n",
       "3                  no       89                        3   \n",
       "4                  no       77                        4   \n",
       "\n",
       "   detention_facility_raion  build_count_mix  railroad_terminal_raion  \\\n",
       "0                        no              0.0                       no   \n",
       "1                        no              0.0                       no   \n",
       "2                        no              0.0                       no   \n",
       "3                        no              2.0                       no   \n",
       "4                        no              1.0                      yes   \n",
       "\n",
       "   __churn  __price_doc  \n",
       "0        0     5.850000  \n",
       "1        0     6.000000  \n",
       "2        0     5.700000  \n",
       "3        0    13.100000  \n",
       "4        0    16.331452  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train_python.csv')\n",
    "test = pd.read_csv('test_python.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639938d1",
   "metadata": {},
   "source": [
    "# Removing outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4f0b78",
   "metadata": {},
   "source": [
    "Удалим из числовых данных выбросы с помощью Quiantile Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4de3c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "for i in train.select_dtypes(include = ['int64', 'float64']).columns:\n",
    "    if i not in['__churn', '__price_doc']: #для всех переменных кроме предсказываемых!!! убираем выбросы\n",
    "        quntile = QuantileTransformer(output_distribution = 'normal')\n",
    "        quntile.fit(train[[i]])\n",
    "        \n",
    "        train[f'f_{i}'] = quntile.transform(train[[i]]) #создаем доп переменные с именами f_старое имя\n",
    "        test[f'f_{i}'] = quntile.transform(test[[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7383df0d",
   "metadata": {},
   "source": [
    "# Refilling nulls with medians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599fe08c",
   "metadata": {},
   "source": [
    "Посмотрим, какие переменные содержат Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8cfd2db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_state                          12014\n",
       "state                            12014\n",
       "f_build_year                     11582\n",
       "build_year                       11582\n",
       "max_floor                         9572\n",
       "f_num_room                        9572\n",
       "f_max_floor                       9572\n",
       "num_room                          9572\n",
       "f_cafe_sum_1000_min_price_avg     4596\n",
       "cafe_sum_1000_min_price_avg       4596\n",
       "f_life_sq                         4193\n",
       "life_sq                           4193\n",
       "build_count_wood                  3063\n",
       "f_build_count_wood                3063\n",
       "build_count_mix                   3063\n",
       "f_build_count_mix                 3063\n",
       "cafe_sum_1500_min_price_avg       2998\n",
       "f_cafe_sum_1500_min_price_avg     2998\n",
       "f_total_trans_amt                 2403\n",
       "0_17_all                          2403\n",
       "f_0_17_all                        2403\n",
       "total_trans_amt                   2403\n",
       "floor                              167\n",
       "f_floor                            167\n",
       "railroad_station_walk_km            10\n",
       "metro_km_walk                       10\n",
       "f_railroad_station_walk_km          10\n",
       "f_metro_km_walk                     10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = (\n",
    "    train\n",
    "    .isnull().sum()                   # count of non-null values\n",
    "    .sort_values(ascending = False)     # sort values using descending order\n",
    ")\n",
    "\n",
    "result[result > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b2a6e1",
   "metadata": {},
   "source": [
    "Заполним пропущенные значения медианами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0bbb0f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1403204896.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  train_modes = train.dropna().median() #считаем медианы для данных без null\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in result[result > 0].index:\n",
    "    train_modes = train.dropna().median() #считаем медианы для данных без null\n",
    "    train[i].fillna(train_modes[i], inplace = True)\n",
    "    \n",
    "    test[i].fillna(train_modes[i], inplace = True) #заполняем в тесте пропуски медианными данными из трейна!!!\n",
    "\n",
    "    \n",
    "result1 = train.isnull().sum().sort_values()\n",
    "result1[result1 > 0]\n",
    "\n",
    "result2 = test.isnull().sum().sort_values()\n",
    "result2[result2 > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25458040",
   "metadata": {},
   "source": [
    "# Target Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4610556d",
   "metadata": {},
   "source": [
    "Target Encoder: \n",
    "\n",
    "Числовые переменные разбиваем на бины с одинаковым количеством наблюдений. Каждому бину присваиваем среднее значение по price и churn!!! (по таргетной переменной)\n",
    "\n",
    "То есть у нас теперь для всех наблюдений в одном бине одно значение - среднее по таргетной переменной для этого бина.\n",
    "\n",
    "\n",
    "Потом эти переменные передаем в регрессию, и как бы сама регрессия линейная, но переменная не совсем линейная.\n",
    "Переменная становится более резкой, и так модель лучше будет работать. Можно поэкспериментировать с количеством бинов, но в целом, чем больше данных, тем больше должно быть бинов\n",
    "\n",
    "\n",
    "Для категориальных можно как Target Encoder, так и One-Hot. Для числовых - Target Hot, Standard Scaler, Robust Scaler (лучше все вместе пхпх)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb8c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd42dc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  5.,  9., 12., 16., 17., 48.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#посмотрим для одной переменной сначала как выглядят эти бины, потом реализуем для всех ньюмерик переменных\n",
    "num_quantiles = 10\n",
    "_, bins_try = pd.qcut(train['max_floor'],\n",
    "                  q = num_quantiles,\n",
    "                  retbins = True, duplicates = 'drop') #важно добавить drop потому что некоторые бины имеют одну границу и код ломается\n",
    "bins_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "896a65f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'boards_{i}'] = pd.cut(test[i], bins = bins).astype(str)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'PRICE_{i}'] = enc.transform(train[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'PRICE_{i}'] = enc.transform(test[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'CHURN_{i}'] = enc.transform(train[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'CHURN_{i}'] = enc.transform(test[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'boards_{i}'] = pd.cut(train[i], bins = bins).astype(str)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'boards_{i}'] = pd.cut(test[i], bins = bins).astype(str)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'PRICE_{i}'] = enc.transform(train[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'PRICE_{i}'] = enc.transform(test[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'CHURN_{i}'] = enc.transform(train[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'CHURN_{i}'] = enc.transform(test[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'boards_{i}'] = pd.cut(train[i], bins = bins).astype(str)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'boards_{i}'] = pd.cut(test[i], bins = bins).astype(str)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'PRICE_{i}'] = enc.transform(train[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'PRICE_{i}'] = enc.transform(test[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'CHURN_{i}'] = enc.transform(train[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'CHURN_{i}'] = enc.transform(test[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'boards_{i}'] = pd.cut(train[i], bins = bins).astype(str)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'boards_{i}'] = pd.cut(test[i], bins = bins).astype(str)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'PRICE_{i}'] = enc.transform(train[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'PRICE_{i}'] = enc.transform(test[f'boards_{i}'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'CHURN_{i}'] = enc.transform(train[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'CHURN_{i}'] = enc.transform(test[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'boards_{i}'] = pd.cut(train[i], bins = bins).astype(str)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'boards_{i}'] = pd.cut(test[i], bins = bins).astype(str)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'PRICE_{i}'] = enc.transform(train[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'PRICE_{i}'] = enc.transform(test[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'CHURN_{i}'] = enc.transform(train[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'CHURN_{i}'] = enc.transform(test[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'boards_{i}'] = pd.cut(train[i], bins = bins).astype(str)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'boards_{i}'] = pd.cut(test[i], bins = bins).astype(str)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'PRICE_{i}'] = enc.transform(train[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'PRICE_{i}'] = enc.transform(test[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'CHURN_{i}'] = enc.transform(train[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'CHURN_{i}'] = enc.transform(test[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'boards_{i}'] = pd.cut(train[i], bins = bins).astype(str)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'boards_{i}'] = pd.cut(test[i], bins = bins).astype(str)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'PRICE_{i}'] = enc.transform(train[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'PRICE_{i}'] = enc.transform(test[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train[f'CHURN_{i}'] = enc.transform(train[f'boards_{i}'])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\3240603760.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test[f'CHURN_{i}'] = enc.transform(test[f'boards_{i}'])\n"
     ]
    }
   ],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "\n",
    "for i in train.select_dtypes(include = ['int64', 'float64']).columns:\n",
    "    if i not in ['__churn', '__price_doc']:\n",
    "        \n",
    "        #сделаем Target Encoding только на преобразованных переменных, без выбросов\n",
    "        if i not in ['max_floor', 'state', 'total_revolving_bal', 'market_count_1500',\n",
    "       'leisure_count_3000', 'total_ct_chng_q4_q1', 'railroad_station_walk_km',\n",
    "       'contacts_count_12_mon', '0_17_all', 'trc_count_2000',\n",
    "       'build_count_wood', 'credit_limit', 'total_trans_ct',\n",
    "       'leisure_count_5000', 'life_sq', 'cafe_count_1000_price_1000',\n",
    "       'mkad_km', 'school_education_centers_top_20_raion',\n",
    "       'avg_utilization_ratio', 'public_transport_station_min_walk',\n",
    "       'customer_age', 'detention_facility_km', 'sport_count_2000',\n",
    "       'cafe_sum_1000_min_price_avg', 'total_amt_chng_q4_q1', 'metro_km_walk',\n",
    "       'office_sqm_5000', 'total_trans_amt', 'months_inactive_12_mon',\n",
    "       'cafe_sum_1500_min_price_avg', 'floor', 'num_room', 'months_on_book',\n",
    "       'dependent_count', 'avg_open_to_buy', 'build_year', 'full_sq',\n",
    "       'total_relationship_count', 'build_count_mix']:\n",
    "            \n",
    "            num_quantiles = 10\n",
    "            _, bins = pd.qcut(train[i],\n",
    "                              q = num_quantiles,\n",
    "                              retbins = True, duplicates = 'drop') #разделили на границы бинов\n",
    "            train[f'boards_{i}'] = pd.cut(train[i], bins = bins).astype(str)\n",
    "            test[f'boards_{i}'] = pd.cut(test[i], bins = bins).astype(str)\n",
    "            \n",
    "            enc = TargetEncoder()\n",
    "            enc.fit(train[f'boards_{i}'], train['__price_doc']) #посчитали среднее по price_doc\n",
    "\n",
    "            train[f'PRICE_{i}'] = enc.transform(train[f'boards_{i}'])\n",
    "            test[f'PRICE_{i}'] = enc.transform(test[f'boards_{i}'])\n",
    "\n",
    "\n",
    "            enc = TargetEncoder()\n",
    "            enc.fit(train[f'boards_{i}'], train['__churn']) #посчитали среднее по churn\n",
    "\n",
    "            train[f'CHURN_{i}'] = enc.transform(train[f'boards_{i}'])\n",
    "            test[f'CHURN_{i}'] = enc.transform(test[f'boards_{i}'])\n",
    "        \n",
    "#сделали Target Encoding для всех numeric переменных. Сначала разделили каждую на 10 бинов\n",
    "#потом посчитали среднее значение целевой переменной для каждого бина"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f4e3432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#чтобы не было 100 переменных уалим  вспомогатльные, которые содержат слово boards\n",
    "\n",
    "train = train[train.columns.drop(list(train.filter(regex = 'boards')))]\n",
    "test = test[test.columns.drop(list(test.filter(regex = 'boards')))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35411556",
   "metadata": {},
   "source": [
    "# Z-score standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3022ae17",
   "metadata": {},
   "source": [
    "Стандартизуем переменные, чтобы они имели распределение от -1 до 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7adda49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[f'Zscore_{i}'] = tr_sc.transform(train[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[f'Zscore_{i}'] = tr_sc.transform(train[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[f'Zscore_{i}'] = tr_sc.transform(train[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[f'Zscore_{i}'] = tr_sc.transform(train[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7644\\1338323512.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for i in train.select_dtypes(include = ['int64', 'float64']).columns:\n",
    "    if i not in ['__churn', '__price_doc']:\n",
    "        \n",
    "        if i not in ['max_floor', 'state', 'total_revolving_bal', 'market_count_1500',\n",
    "       'leisure_count_3000', 'total_ct_chng_q4_q1', 'railroad_station_walk_km',\n",
    "       'contacts_count_12_mon', '0_17_all', 'trc_count_2000',\n",
    "       'build_count_wood', 'credit_limit', 'total_trans_ct',\n",
    "       'leisure_count_5000', 'life_sq', 'cafe_count_1000_price_1000',\n",
    "       'mkad_km', 'school_education_centers_top_20_raion',\n",
    "       'avg_utilization_ratio', 'public_transport_station_min_walk',\n",
    "       'customer_age', 'detention_facility_km', 'sport_count_2000',\n",
    "       'cafe_sum_1000_min_price_avg', 'total_amt_chng_q4_q1', 'metro_km_walk',\n",
    "       'office_sqm_5000', 'total_trans_amt', 'months_inactive_12_mon',\n",
    "       'cafe_sum_1500_min_price_avg', 'floor', 'num_room', 'months_on_book',\n",
    "       'dependent_count', 'avg_open_to_buy', 'build_year', 'full_sq',\n",
    "       'total_relationship_count', 'build_count_mix']:\n",
    "                     \n",
    "            tr_sc = StandardScaler()\n",
    "            tr_sc.fit(train[[i]])\n",
    "\n",
    "            train[f'Zscore_{i}'] = tr_sc.transform(train[[i]])\n",
    "            test[f'Zscore_{i}'] = tr_sc.transform(test[[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc7d7aa",
   "metadata": {},
   "source": [
    "# One-Hot Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28509d49",
   "metadata": {},
   "source": [
    "One-Hot Encoder - для категориальных переменных используем\n",
    "\n",
    "Он трансформирует все категориальные переменные в дамми по сути"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a7a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8c126835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot = OneHotEncoder(sparse = False, handle_unknown='ignore')\n",
    "\n",
    "for i in train.select_dtypes(include = ['object']).columns:\n",
    "    if i != 'timestamp':\n",
    "        onehot.fit(train[[i]])\n",
    "        values_train = onehot.transform(train[[i]])\n",
    "        values_test = onehot.transform(test[[i]])\n",
    "        list_names = []\n",
    "        \n",
    "        for k, cat in enumerate(onehot.categories_[0]):\n",
    "            name = f'f_{i}_{cat}'\n",
    "            list_names.append(name)\n",
    "            train[name] = values_train[:, k]\n",
    "            test[name] = values_test[:, k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5db68b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_floor</th>\n",
       "      <th>state</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>big_market_raion</th>\n",
       "      <th>total_revolving_bal</th>\n",
       "      <th>market_count_1500</th>\n",
       "      <th>leisure_count_3000</th>\n",
       "      <th>total_ct_chng_q4_q1</th>\n",
       "      <th>water_1line</th>\n",
       "      <th>railroad_station_walk_km</th>\n",
       "      <th>...</th>\n",
       "      <th>f_railroad_1line_no</th>\n",
       "      <th>f_railroad_1line_yes</th>\n",
       "      <th>f_education_level_Graduate</th>\n",
       "      <th>f_education_level_High School</th>\n",
       "      <th>f_incineration_raion_no</th>\n",
       "      <th>f_incineration_raion_yes</th>\n",
       "      <th>f_detention_facility_raion_no</th>\n",
       "      <th>f_detention_facility_raion_yes</th>\n",
       "      <th>f_railroad_terminal_raion_no</th>\n",
       "      <th>f_railroad_terminal_raion_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>no</td>\n",
       "      <td>1906</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.694</td>\n",
       "      <td>no</td>\n",
       "      <td>5.419893</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>no</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.693</td>\n",
       "      <td>no</td>\n",
       "      <td>3.411993</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>no</td>\n",
       "      <td>2153</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.831</td>\n",
       "      <td>no</td>\n",
       "      <td>1.277658</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>no</td>\n",
       "      <td>1806</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.638</td>\n",
       "      <td>no</td>\n",
       "      <td>4.291432</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>no</td>\n",
       "      <td>753</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.902</td>\n",
       "      <td>no</td>\n",
       "      <td>0.853960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_floor  state marital_status big_market_raion  total_revolving_bal  \\\n",
       "0       12.0    2.0         Single               no                 1906   \n",
       "1       12.0    2.0        Married               no                   12   \n",
       "2       12.0    2.0        Married               no                 2153   \n",
       "3       12.0    2.0        Married               no                 1806   \n",
       "4       12.0    2.0        Married               no                  753   \n",
       "\n",
       "   market_count_1500  leisure_count_3000  total_ct_chng_q4_q1 water_1line  \\\n",
       "0                  1                   0                0.694          no   \n",
       "1                  0                   6                0.693          no   \n",
       "2                  5                   0                0.831          no   \n",
       "3                  2                   0                0.638          no   \n",
       "4                  2                  40                0.902          no   \n",
       "\n",
       "   railroad_station_walk_km  ... f_railroad_1line_no  f_railroad_1line_yes  \\\n",
       "0                  5.419893  ...                 1.0                   0.0   \n",
       "1                  3.411993  ...                 1.0                   0.0   \n",
       "2                  1.277658  ...                 1.0                   0.0   \n",
       "3                  4.291432  ...                 1.0                   0.0   \n",
       "4                  0.853960  ...                 0.0                   1.0   \n",
       "\n",
       "   f_education_level_Graduate  f_education_level_High School  \\\n",
       "0                         1.0                            0.0   \n",
       "1                         1.0                            0.0   \n",
       "2                         1.0                            0.0   \n",
       "3                         1.0                            0.0   \n",
       "4                         1.0                            0.0   \n",
       "\n",
       "  f_incineration_raion_no  f_incineration_raion_yes  \\\n",
       "0                     1.0                       0.0   \n",
       "1                     1.0                       0.0   \n",
       "2                     1.0                       0.0   \n",
       "3                     1.0                       0.0   \n",
       "4                     1.0                       0.0   \n",
       "\n",
       "   f_detention_facility_raion_no  f_detention_facility_raion_yes  \\\n",
       "0                            1.0                             0.0   \n",
       "1                            1.0                             0.0   \n",
       "2                            1.0                             0.0   \n",
       "3                            1.0                             0.0   \n",
       "4                            1.0                             0.0   \n",
       "\n",
       "   f_railroad_terminal_raion_no  f_railroad_terminal_raion_yes  \n",
       "0                           1.0                            0.0  \n",
       "1                           1.0                            0.0  \n",
       "2                           1.0                            0.0  \n",
       "3                           1.0                            0.0  \n",
       "4                           0.0                            1.0  \n",
       "\n",
       "[5 rows x 341 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
